# üìù Anota√ß√µes Relevantes: Computabilidade - Aula 2

## **1. A Import√¢ncia de Medir a Efici√™ncia de Algoritmos**

* Algoritmos eficientes s√£o t√£o importantes quanto hardware potente. Muitas vezes, o algoritmo correto supera o impacto de ter m√°quinas mais r√°pidas.
* Para volumes grandes de dados, um algoritmo eficiente pode reduzir drasticamente o tempo de processamento e custo computacional.
* Melhorias na efici√™ncia algor√≠tmica traduzem-se em economia de recursos, energia e tempo.

## **2. Como Medir a Efici√™ncia: Contagem de Passos**

* "Passos" s√£o opera√ß√µes elementares executadas pelo algoritmo, como:

  * Atribui√ß√µes de vari√°veis.
  * Compara√ß√µes l√≥gicas.
  * Opera√ß√µes aritm√©ticas b√°sicas.
  * Acessos √† mem√≥ria (leitura/escrita).
* Vantagens da contagem de passos:

  * √â uma medida independente do hardware espec√≠fico.
  * Permite uma compara√ß√£o objetiva entre algoritmos.
  * Foca no comportamento √† medida que a entrada (n) cresce.
  * Ajuda a identificar gargalos e oportunidades de otimiza√ß√£o.

### **Exemplos em python:**

```python-repl
import os
os.system('cls' if os.name == 'nt' else 'clear')
n = 5
for i in range(1, n+1):
    for j in range(1, i+1):
        print(i, j)
```

Para n = 5, temos:
5 * 2 / 2 = 15 execu√ß√µes
Portanto, a complexidade √© O(n¬≤), mesmo sendo menos execu√ß√µes que um loop duplo completo (n¬≤).

## **3. Por que a Contagem de Passos √© Melhor que Medir em "Segundos"?**

* O tempo real de execu√ß√£o varia dependendo de fatores como hardware (processador, mem√≥ria, cache), sistema operacional, e compilador.
* A contagem de passos √© uma m√©trica port√°vel e compar√°vel entre diferentes ambientes.
* Medidas de tempo em segundos s√£o √∫teis como experimentos para validar an√°lises te√≥ricas, desde que realizadas na mesma m√°quina e condi√ß√µes.

### **Medindo o tempo de execu√ß√£o:**

Utilizando time.time() em Python

```
import os, time
os.system('cls' if os.name == 'nt' else 'clear')
n = 100000
inicio = time.time()
soma = 0
for i in range(n):
    soma += i
fim = time.time()
print(f"Tempo de execu√ß√£o: {fim - inicio:.6f} s")
print(f"Soma total = {soma}")
```

**Esta abordagem √© √∫til para comparar algoritmos executados na mesma m√°quina, complementando a an√°lise te√≥rica com dados reais.**

## **4. Ordem de Crescimento e Nota√ß√£o Big-O**

* A ordem de crescimento descreve como o n√∫mero de passos de um algoritmo aumenta em rela√ß√£o ao tamanho da entrada (n), especialmente quando n √© grande.
* As caracter√≠sticas principais da an√°lise de ordem de crescimento s√£o:
  * Focar no comportamento para n grande.
  * Ignorar constantes multiplicativas.
  * Considerar apenas o termo de maior crescimento.
* A Nota√ß√£o Big-O √© uma forma matem√°tica de descrever o crescimento do tempo de execu√ß√£o de um algoritmo em fun√ß√£o do tamanho da entrada n, quando n fica muito grande.
* **$O(g(n))$** representa um limite superior para o crescimento de uma fun√ß√£o quando n √© suficientemente grande.
* A an√°lise com Big-O descreve o limite superior ou o pior cen√°rio, ignora constantes e termos de menor ordem, e foca na taxa de crescimento em vez de segundos exatos. Um crescimento menor indica um algoritmo mais escal√°vel.

## **5. Classes Comuns de Complexidade**

| Nota√ß√£o                 | Nome         | Descri√ß√£o                                                                                                            | Exemplo                                               |
| :------------------------ | :----------- | :--------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------- |
| **$O(1)$**        | Constante    | O tempo de execu√ß√£o √© fixo, independente do tamanho da entrada.                                                     | Acessar um elemento em um array.                      |
| **$O(\log n)$**   | Logar√≠tmica | O tempo de execu√ß√£o cresce muito lentamente com o tamanho da entrada, tipicamente ao dividir o problema pela metade. | Busca bin√°ria.                                       |
| **$O(n)$**        | Linear       | O tempo de execu√ß√£o cresce proporcionalmente ao tamanho da entrada.                                                  | Percorrer todos os elementos de uma lista.            |
| **$O(n \log n)$** | Quase-linear | Um crescimento um pouco maior que o linear, comum em algoritmos eficientes de ordena√ß√£o.                             | Merge sort, Quick sort (caso m√©dio).                 |
| **$O(n^2)$**      | Quadr√°tica  | O tempo de execu√ß√£o cresce ao quadrado do tamanho da entrada, geralmente devido a loops aninhados.                   | Dois loops aninhados iterando sobre a mesma entrada.  |
| **$O(2^n)$**      | Exponencial  | O tempo de execu√ß√£o dobra a cada adi√ß√£o √† entrada, tornando-o invi√°vel para grandes volumes de dados.            | Resolver o problema de subconjuntos por for√ßa bruta. |
